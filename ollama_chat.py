#!/usr/bin/env python3
"""èˆ‡ Ollama äº’å‹•å°è©±ç³»çµ±"""

import requests
import json
import sys
from datetime import datetime

class OllamaChat:
    def __init__(self, model="gpt-oss:latest"):
        self.ollama_url = "http://192.168.53.254:11434"
        self.model = model
        self.conversation_history = []
        
    def chat(self, user_input):
        """ç™¼é€è¨Šæ¯çµ¦ Ollama ä¸¦ç²å–å›æ‡‰"""
        # åŠ å…¥ä½¿ç”¨è€…è¨Šæ¯åˆ°å°è©±æ­·å²
        self.conversation_history.append({
            "role": "user",
            "content": user_input
        })
        
        try:
            response = requests.post(
                f"{self.ollama_url}/api/chat",
                json={
                    "model": self.model,
                    "messages": self.conversation_history,
                    "stream": False
                }
            )
            
            if response.status_code == 200:
                result = response.json()
                assistant_message = result.get('message', {}).get('content', 'ç„¡å›æ‡‰')
                
                # åŠ å…¥åŠ©æ‰‹å›æ‡‰åˆ°å°è©±æ­·å²
                self.conversation_history.append({
                    "role": "assistant",
                    "content": assistant_message
                })
                
                return assistant_message
            else:
                return f"éŒ¯èª¤: HTTP {response.status_code}"
                
        except Exception as e:
            return f"é€£ç·šéŒ¯èª¤: {str(e)}"
    
    def clear_history(self):
        """æ¸…é™¤å°è©±æ­·å²"""
        self.conversation_history = []
        print("å°è©±æ­·å²å·²æ¸…é™¤")
    
    def save_conversation(self):
        """å„²å­˜å°è©±è¨˜éŒ„"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"conversation_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump({
                "model": self.model,
                "timestamp": timestamp,
                "messages": self.conversation_history
            }, f, ensure_ascii=False, indent=2)
        
        print(f"å°è©±å·²å„²å­˜åˆ°: {filename}")

def main():
    print("ğŸ¤– Ollama å°è©±ç³»çµ±")
    print("="*50)
    print("å¯ç”¨æŒ‡ä»¤:")
    print("  /quit æˆ– /exit - çµæŸå°è©±")
    print("  /clear - æ¸…é™¤å°è©±æ­·å²")
    print("  /save - å„²å­˜å°è©±è¨˜éŒ„")
    print("  /model - åˆ‡æ›æ¨¡å‹")
    print("="*50)
    
    chat = OllamaChat()
    print(f"ä½¿ç”¨æ¨¡å‹: {chat.model}")
    print("\né–‹å§‹å°è©±...")
    
    while True:
        try:
            # ç²å–ä½¿ç”¨è€…è¼¸å…¥
            user_input = input("\næ‚¨: ").strip()
            
            # è™•ç†ç‰¹æ®ŠæŒ‡ä»¤
            if user_input.lower() in ['/quit', '/exit']:
                print("å†è¦‹ï¼")
                break
            elif user_input.lower() == '/clear':
                chat.clear_history()
                continue
            elif user_input.lower() == '/save':
                chat.save_conversation()
                continue
            elif user_input.lower() == '/model':
                print("\nå¯ç”¨æ¨¡å‹:")
                print("1. gpt-oss:latest")
                print("2. llama3:70b")
                print("3. gemma3:12b")
                print("4. gemma3:27b")
                choice = input("é¸æ“‡æ¨¡å‹ (1-4): ")
                models = ["gpt-oss:latest", "llama3:70b", "gemma3:12b", "gemma3:27b"]
                if choice.isdigit() and 1 <= int(choice) <= 4:
                    chat.model = models[int(choice)-1]
                    print(f"å·²åˆ‡æ›åˆ°: {chat.model}")
                continue
            
            if not user_input:
                continue
            
            # ç™¼é€è¨Šæ¯ä¸¦ç²å–å›æ‡‰
            print("\nOllama: ", end="", flush=True)
            response = chat.chat(user_input)
            print(response)
            
        except KeyboardInterrupt:
            print("\n\nä¸­æ–·å°è©±")
            break
        except Exception as e:
            print(f"\néŒ¯èª¤: {str(e)}")

if __name__ == "__main__":
    main()