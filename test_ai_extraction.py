#!/usr/bin/env python3
"""
ä½¿ç”¨AIæ¨¡å‹æå–æ‹›æ¨™æ–‡ä»¶ä¸­çš„æ¡ˆè™Ÿå’Œæ¡ˆå
"""
import json
import requests
import zipfile
import re
import os

class AIDocumentExtractor:
    def __init__(self):
        self.ollama_url = "http://192.168.53.14:11434"
        self.model = "gpt-oss:latest"
    
    def extract_odt_content(self, file_path: str) -> str:
        """æå–ODTå…§å®¹"""
        try:
            with zipfile.ZipFile(file_path, 'r') as zip_file:
                content_xml = zip_file.read('content.xml').decode('utf-8')
                # ç§»é™¤XMLæ¨™ç±¤
                clean_text = re.sub(r'<[^>]+>', ' ', content_xml)
                clean_text = re.sub(r'\s+', ' ', clean_text).strip()
                return clean_text
        except Exception as e:
            print(f"âŒ è®€å–ODTæª”æ¡ˆå¤±æ•—ï¼š{e}")
            return ""
    
    def call_ai_model(self, prompt: str) -> str:
        """å‘¼å«AIæ¨¡å‹"""
        try:
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "stream": False,
                    "temperature": 0.1  # é™ä½æº«åº¦ä»¥æé«˜æº–ç¢ºæ€§
                }
            )
            if response.status_code == 200:
                return response.json().get('response', '')
            else:
                return f"éŒ¯èª¤: {response.status_code}"
        except Exception as e:
            return f"å‘¼å«å¤±æ•—: {str(e)}"
    
    def extract_with_ai(self, document_content: str, doc_type: str) -> dict:
        """ä½¿ç”¨AIæ¨¡å‹æå–è³‡è¨Š"""
        
        # åˆ†é è™•ç†ï¼ˆæ¯é ç´„2000å­—ï¼‰
        page_size = 2000
        pages = [document_content[i:i+page_size] for i in range(0, len(document_content), page_size)]
        
        # é‡å°ç¬¬ä¸€é ï¼ˆé€šå¸¸åŒ…å«æ¡ˆè™Ÿæ¡ˆåï¼‰
        first_page = pages[0] if pages else document_content
        
        # è¨­è¨ˆæç¤ºè©
        if doc_type == "æ‹›æ¨™å…¬å‘Š":
            prompt = f"""è«‹å¾ä»¥ä¸‹æ‹›æ¨™å…¬å‘Šå…§å®¹ä¸­æå–è³‡è¨Šï¼Œä¸¦ä»¥JSONæ ¼å¼å›ç­”ã€‚
å¦‚æœæ‰¾ä¸åˆ°å°æ‡‰è³‡æ–™ï¼Œè«‹å¡«å…¥"NA"ã€‚

éœ€è¦æå–çš„è³‡è¨Šï¼š
1. æ¡ˆè™Ÿ - å°‹æ‰¾"æ¡ˆè™Ÿï¼š"å¾Œé¢çš„ç·¨è™Ÿï¼ˆæ ¼å¼é€šå¸¸ç‚ºCé–‹é ­ï¼Œå¦‚C14A00139ï¼‰
2. æ¡ˆå - å°‹æ‰¾"æ¡ˆåï¼š"å¾Œé¢çš„åç¨±

æ–‡ä»¶å…§å®¹ï¼š
{first_page}

è«‹åªå›ç­”ä»¥ä¸‹JSONæ ¼å¼ï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—ï¼š
{{
  "æ¡ˆè™Ÿ": "ç·¨è™Ÿæˆ–NA",
  "æ¡ˆå": "åç¨±æˆ–NA"
}}"""
        else:  # æŠ•æ¨™é ˆçŸ¥
            prompt = f"""è«‹å¾ä»¥ä¸‹æŠ•æ¨™é ˆçŸ¥å…§å®¹ä¸­æå–è³‡è¨Šï¼Œä¸¦ä»¥JSONæ ¼å¼å›ç­”ã€‚
å¦‚æœæ‰¾ä¸åˆ°å°æ‡‰è³‡æ–™ï¼Œè«‹å¡«å…¥"NA"ã€‚

éœ€è¦æå–çš„è³‡è¨Šï¼š
1. æ¡ˆè™Ÿ - å°‹æ‰¾"æ¡è³¼æ¨™çš„åç¨±åŠæ¡ˆè™Ÿ"ç« ç¯€ä¸­çš„æ¡ˆè™Ÿï¼ˆæ ¼å¼é€šå¸¸ç‚ºCé–‹é ­ï¼‰
2. æ¡ˆå - å°‹æ‰¾"æ¡è³¼æ¨™çš„åç¨±åŠæ¡ˆè™Ÿ"ç« ç¯€ä¸­çš„æ¡è³¼æ¨™çš„åç¨±

æ–‡ä»¶å…§å®¹ï¼š
{first_page}

è«‹åªå›ç­”ä»¥ä¸‹JSONæ ¼å¼ï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—ï¼š
{{
  "æ¡ˆè™Ÿ": "ç·¨è™Ÿæˆ–NA",
  "æ¡ˆå": "åç¨±æˆ–NA"
}}"""
        
        # å‘¼å«AIæ¨¡å‹
        print(f"ğŸ¤– æ­£åœ¨ä½¿ç”¨AIæ¨¡å‹åˆ†æ{doc_type}...")
        ai_response = self.call_ai_model(prompt)
        
        # è§£æAIå›æ‡‰
        try:
            # å˜—è©¦æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{[^}]+\}', ai_response)
            if json_match:
                result = json.loads(json_match.group())
            else:
                result = {"æ¡ˆè™Ÿ": "è§£æå¤±æ•—", "æ¡ˆå": "è§£æå¤±æ•—"}
        except:
            result = {"æ¡ˆè™Ÿ": "JSONè§£æéŒ¯èª¤", "æ¡ˆå": "JSONè§£æéŒ¯èª¤"}
        
        return result

def main():
    """ä¸»ç¨‹å¼"""
    case_id = "C14A00139"
    case_folder = f"/Users/ada/Desktop/ollama/{case_id}"
    
    extractor = AIDocumentExtractor()
    
    # è®€å–æ‹›æ¨™å…¬å‘Š
    announcement_file = f"{case_folder}/é™„ä»¶1.å…¬é–‹å–å¾—å ±åƒ¹æˆ–ä¼åŠƒæ›¸å…¬å‘Šäº‹é …(è²¡ç‰©)-1120504ç‰ˆ_éŒ¯.odt"
    announcement_content = extractor.extract_odt_content(announcement_file)
    
    # è®€å–æŠ•æ¨™é ˆçŸ¥
    instructions_file = f"{case_folder}/é™„ä»¶2.è‡ºåŒ—å¤§çœ¾æ·é‹è‚¡ä»½æœ‰é™å…¬å¸æŠ•æ¨™é ˆçŸ¥(ä¸€èˆ¬ç‰ˆ)(ä¸å«æŠ•æ¨™é ˆçŸ¥ç¯„æœ¬é™„éŒ„)_éŒ¯.odt"
    instructions_content = extractor.extract_odt_content(instructions_file)
    
    # ä½¿ç”¨AIæ¨¡å‹æå–
    ann_result = extractor.extract_with_ai(announcement_content[:3000], "æ‹›æ¨™å…¬å‘Š")
    ins_result = extractor.extract_with_ai(instructions_content[:3000], "æŠ•æ¨™é ˆçŸ¥")
    
    # æ•´åˆçµæœ
    final_result = {
        "æ‹›æ¨™å…¬å‘Šçš„æ¡ˆè™Ÿ": ann_result.get("æ¡ˆè™Ÿ", "NA"),
        "æ‹›æ¨™å…¬å‘Šçš„æ¡ˆå": ann_result.get("æ¡ˆå", "NA"),
        "æŠ•æ¨™é ˆçŸ¥çš„æ¡ˆè™Ÿ": ins_result.get("æ¡ˆè™Ÿ", "NA"),
        "æŠ•æ¨™é ˆçŸ¥çš„æ¡ˆå": ins_result.get("æ¡ˆå", "NA")
    }
    
    print("\nğŸ“Š AIæ¨¡å‹æå–çµæœï¼š")
    print(json.dumps(final_result, ensure_ascii=False, indent=2))
    
    # é¡¯ç¤ºé æœŸçµæœï¼ˆåŸºæ–¼è¦å‰‡çš„æå–ï¼‰
    expected_result = {
        "æ‹›æ¨™å…¬å‘Šçš„æ¡ˆè™Ÿ": "C14A00139",
        "æ‹›æ¨™å…¬å‘Šçš„æ¡ˆå": "æ”œå¸¶å¼æ•¸ä½ç„¡ç·šé›»ç¶œåˆæ¸¬è©¦å„€æ¡è³¼",
        "æŠ•æ¨™é ˆçŸ¥çš„æ¡ˆè™Ÿ": "C13A00139",
        "æŠ•æ¨™é ˆçŸ¥çš„æ¡ˆå": "æ”œå¸¶å¼æ•¸ä½ç„¡ç·šé›»ç¶œåˆæ¸¬è©¦å„€æ¡è³¼"
    }
    
    print("\nâœ… é æœŸçµæœï¼ˆè¦å‰‡æå–ï¼‰ï¼š")
    print(json.dumps(expected_result, ensure_ascii=False, indent=2))
    
    # æ¯”è¼ƒå·®ç•°
    print("\nğŸ” å·®ç•°åˆ†æï¼š")
    for key in expected_result:
        if final_result.get(key) != expected_result[key]:
            print(f"âŒ {key}: AIæå–'{final_result.get(key)}' vs é æœŸ'{expected_result[key]}'")
        else:
            print(f"âœ… {key}: ä¸€è‡´")

if __name__ == "__main__":
    main()